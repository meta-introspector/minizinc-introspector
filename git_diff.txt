diff --git a/Cargo.lock b/Cargo.lock
index bbb35dbcd..ae4d190b1 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -2650,6 +2650,7 @@ dependencies = [
  "poem_traits",
  "regex",
  "serde",
+ "serde_json",
  "serde_yaml",
  "tempfile",
  "toml 0.5.11",
diff --git a/crates/poem_yaml_fixer/Cargo.toml b/crates/poem_yaml_fixer/Cargo.toml
index 428e20a84..094279017 100644
--- a/crates/poem_yaml_fixer/Cargo.toml
+++ b/crates/poem_yaml_fixer/Cargo.toml
@@ -16,4 +16,5 @@ once_cell = "1.19"
 linkme = "0.3"
 grex = { path = "../../vendor/grex" }
 poem_traits = { path = "../poem_traits" }
-tempfile = "3.10.1"
\ No newline at end of file
+tempfile = "3.10.1"
+serde_json = "1.0"
\ No newline at end of file
diff --git a/crates/poem_yaml_fixer/src/functions/error_handling/handle_unmatched_regex_error.rs b/crates/poem_yaml_fixer/src/functions/error_handling/handle_unmatched_regex_error.rs
index 41836caa3..31d108ec5 100644
--- a/crates/poem_yaml_fixer/src/functions/error_handling/handle_unmatched_regex_error.rs
+++ b/crates/poem_yaml_fixer/src/functions/error_handling/handle_unmatched_regex_error.rs
@@ -1,27 +1,28 @@
 use anyhow::{Result, anyhow};
-use grex::RegExpBuilder;
+use serde::{Serialize, Deserialize};
+use serde_json;
 
-pub fn handle_unmatched_regex_error(file_path: &std::path::PathBuf, error_message: &str) -> Result<()> {
-    eprintln!("Error fixing {file_path:?}: {error_message}\n");
+// Define the new struct for rich error context
+#[derive(Debug, Serialize, Deserialize)]
+pub struct RegexMatchErrorContext {
+    pub file_path: String,
+    pub line_number: usize,
+    pub line_content: String,
+    pub context_before: Vec<String>,
+    pub context_after: Vec<String>,
+    pub parsing_state: String,
+    pub current_tree_path: Vec<String>,
+    pub error_message: String,
+}
 
-    let unmatched_line = error_message.trim_start_matches("No regex matched line: ");
+// Modify the function signature to accept the new context struct
+pub fn handle_unmatched_regex_error(context: RegexMatchErrorContext) -> Result<Vec<String>> {
+    // Serialize the context to JSON and print it
+    let json_context = serde_json::to_string_pretty(&context)?;
+    eprintln!("\n--- Regex Match Error Context (JSON) ---");
+    eprintln!("{}", json_context);
+    eprintln!("----------------------------------------");
 
-    eprintln!("\nAttempting to generate regex for: `{unmatched_line}`");
-    let generated_regex = RegExpBuilder::from(&[unmatched_line])
-        .build();
-
-    eprintln!("Generated Regex: `{generated_regex}`");
-    eprintln!("Please review this regex and add it to your regex config file (e.g., `regex_config.toml`).");
-    eprintln!("Example entry:");
-    eprintln!("```toml");
-    eprintln!("[[regexes]]"); // Added [[regexes]] to indicate array of tables
-    eprintln!("name = \"new_generated_regex\""); // Added a placeholder name
-    eprintln!("pattern = \"{generated_regex}\"");
-    eprintln!("callback_function = \"handle_new_generated_regex\"");
-    eprintln!("```");
-
-    eprintln!("```");
-
-    // Return an error to indicate that an unmatched regex occurred
-    Err(anyhow!("Unmatched regex error for file: {:?}, message: {}", file_path, error_message))
+    // Original error message for compatibility, can be removed later
+    Err(anyhow!("Unmatched regex error for file: \"{}\", message: {}", context.file_path, context.error_message))
 }
\ No newline at end of file
diff --git a/crates/poem_yaml_fixer/src/functions/extract_front_matter.rs b/crates/poem_yaml_fixer/src/functions/extract_front_matter.rs
index fd97b6d9d..0c0f17ffc 100644
--- a/crates/poem_yaml_fixer/src/functions/extract_front_matter.rs
+++ b/crates/poem_yaml_fixer/src/functions/extract_front_matter.rs
@@ -3,6 +3,7 @@
 // the front matter content and the raw poem body from the input text.
 
 use anyhow::{Result, anyhow};
+use crate::functions::types::FixedFrontMatter;
 
 pub fn extract_front_matter(lines: &mut Vec<&str>, content: &str) -> Result<(isize, isize, String, String)> {
     let mut fm_start = -1;
@@ -18,34 +19,49 @@ pub fn extract_front_matter(lines: &mut Vec<&str>, content: &str) -> Result<(isi
         }
     }
 
-    if fm_start != 0 || fm_end == -1 {
+    if fm_start == -1 {
+        // No front matter delimiters found, treat entire content as poem body
+        return Ok((-1, -1, String::new(), content.to_string()));
+    }
+
+    if fm_start != 0 {
         return Err(anyhow!("Invalid Markdown file format (missing or malformed front matter delimiters).\nContent:\n{}", content));
     }
 
-    let front_matter_lines_slice = &lines[(fm_start + 1) as usize .. fm_end as usize];
-    let mut front_matter_str_for_parsing = String::new();
-    let mut extracted_poem_body_from_fm = String::new();
-    let mut in_poem_body_in_fm = false;
-
-    // Manually process front matter lines to extract poem_body if present
-    for line in front_matter_lines_slice.iter() {
-        if line.trim().starts_with("poem_body: |") {
-            in_poem_body_in_fm = true;
-        } else if in_poem_body_in_fm {
-            if line.starts_with(" ") {
-                extracted_poem_body_from_fm.push_str(line.trim_start());
-                extracted_poem_body_from_fm.push('\n');
-            }
-            else {
-                in_poem_body_in_fm = false;
-                front_matter_str_for_parsing.push_str(line);
-                front_matter_str_for_parsing.push('\n');
+    let front_matter_str_for_parsing: String;
+    let extracted_poem_body_from_fm: String;
+
+    if fm_end == -1 {
+        // Case: Missing closing ---. Treat everything after fm_start as front matter.
+        front_matter_str_for_parsing = lines[(fm_start + 1) as usize..].join("\n");
+        extracted_poem_body_from_fm = String::new(); // No separate poem body if closing --- is missing
+    } else {
+        // Case: Both --- delimiters found.
+        let front_matter_lines_slice = &lines[(fm_start + 1) as usize .. fm_end as usize];
+        let mut temp_front_matter_str = String::new();
+        let mut temp_extracted_poem_body = String::new();
+        let mut in_poem_body_in_fm = false;
+
+        // Manually process front matter lines to extract poem_body if present
+        for line in front_matter_lines_slice.iter() {
+            if line.trim().starts_with("poem_body: |") {
+                in_poem_body_in_fm = true;
+            } else if in_poem_body_in_fm {
+                if line.starts_with(" ") {
+                    temp_extracted_poem_body.push_str(line.trim_start());
+                    temp_extracted_poem_body.push('\n');
+                } else {
+                    in_poem_body_in_fm = false;
+                    temp_front_matter_str.push_str(line);
+                    temp_front_matter_str.push('\n');
+                }
+            } else {
+                temp_front_matter_str.push_str(line);
+                temp_front_matter_str.push('\n');
             }
         }
-        else {
-            front_matter_str_for_parsing.push_str(line);
-            front_matter_str_for_parsing.push('\n');
-        }
+        front_matter_str_for_parsing = temp_front_matter_str;
+        extracted_poem_body_from_fm = temp_extracted_poem_body;
     }
 
     Ok((fm_start, fm_end, front_matter_str_for_parsing, extracted_poem_body_from_fm))
diff --git a/crates/poem_yaml_fixer/src/functions/process_memes_with_workflow.rs b/crates/poem_yaml_fixer/src/functions/process_memes_with_workflow.rs
index c46802a50..a2bf24ce8 100644
--- a/crates/poem_yaml_fixer/src/functions/process_memes_with_workflow.rs
+++ b/crates/poem_yaml_fixer/src/functions/process_memes_with_workflow.rs
@@ -2,14 +2,18 @@
 // It processes meme entries in the front matter using a workflow defined by regexes and callbacks.
 
 use std::collections::HashMap;
-use anyhow::{Result, anyhow};
-use regex::Regex; // Removed unused Captures import
+use anyhow::Result;
+use regex::Regex;
+use std::path::PathBuf;
 
-use crate::functions::types::FixedFrontMatter; // Import FixedFrontMatter from the types module
+use crate::functions::types::FixedFrontMatter;
 use poem_traits::RegexConfig;
-use crate::functions::types::PoemFunctionRegistry; // Import FunctionRegistry
+use crate::functions::types::PoemFunctionRegistry;
+use crate::functions::error_handling::handle_unmatched_regex_error::RegexMatchErrorContext;
+use crate::functions::error_handling::handle_unmatched_regex_error::handle_unmatched_regex_error;
 
 pub fn process_memes_with_workflow(
+    file_path: &PathBuf,
     meme_lines: &Vec<String>,
     regex_config: &RegexConfig,
     fixed_fm: &mut FixedFrontMatter,
@@ -22,7 +26,7 @@ pub fn process_memes_with_workflow(
         compiled_regexes.insert(entry.name.clone(), Regex::new(&entry.pattern)?);
     }
 
-    for line in meme_lines {
+    for (line_number, line) in meme_lines.iter().enumerate() {
         let mut matched_any_regex = false;
         for entry in &regex_config.regexes {
             if let Some(regex) = compiled_regexes.get(&entry.name) {
@@ -34,8 +38,7 @@ pub fn process_memes_with_workflow(
                         println!("    Captures: {captures_raw:?}");
                         println!("    Calling function: {}", entry.callback_function);
                     }
-                    matched_regexes.push(entry.name.clone()); // Add matched regex name to report
-                    // Convert captures_raw to Vec<String>
+                    matched_regexes.push(entry.name.clone());
                     let captures: Vec<String> = (0..captures_raw.len())
                         .map(|i| captures_raw.get(i).map_or("", |m| m.as_str()).to_string())
                         .collect();
@@ -45,14 +48,24 @@ pub fn process_memes_with_workflow(
                     } else {
                         eprintln!("Warning: Callback function '{}' not found in registry for regex '{}'", entry.callback_function, entry.name);
                     }
-                    // Assuming only one regex matches per line for now, break after first match
                     break;
                 }
             }
         }
-        // Only return error if no regex matched and the line is not empty
         if !matched_any_regex && !line.trim().is_empty() {
-            return Err(anyhow!("No regex matched line: {}", line));
+            let context = RegexMatchErrorContext {
+                file_path: file_path.to_string_lossy().into_owned(),
+                line_number: line_number + 1,
+                line_content: line.clone(),
+                context_before: if line_number > 0 {
+                    meme_lines[0..line_number].iter().rev().take(3).map(|s| s.to_string()).collect::<Vec<String>>().into_iter().rev().collect()
+                } else { Vec::new() },
+                context_after: meme_lines.iter().skip(line_number + 1).take(3).map(|s| s.to_string()).collect(),
+                parsing_state: "processing_meme_lines".to_string(),
+                current_tree_path: Vec::new(),
+                error_message: format!("No regex matched line: {}", line),
+            };
+            return handle_unmatched_regex_error(context);
         }
     }
     Ok(matched_regexes)
diff --git a/crates/poem_yaml_fixer/src/functions/process_single_poem_file_for_report.rs b/crates/poem_yaml_fixer/src/functions/process_single_poem_file_for_report.rs
index 4569e0ece..4fd7178ef 100644
--- a/crates/poem_yaml_fixer/src/functions/process_single_poem_file_for_report.rs
+++ b/crates/poem_yaml_fixer/src/functions/process_single_poem_file_for_report.rs
@@ -30,6 +30,7 @@ pub fn process_single_poem_file_for_report(
     // Call process_memes_with_workflow
     let meme_lines: Vec<String> = poem_body.lines().map(|s| s.to_string()).collect();
     let process_memes_result = process_memes_with_workflow::process_memes_with_workflow(
+        file_path,
         &meme_lines,
         regex_config,
         &mut fixed_fm,
@@ -40,9 +41,9 @@ pub fn process_single_poem_file_for_report(
     let matched_regexes = if let Ok(m) = process_memes_result {
         m
     } else if let Err(e) = process_memes_result {
-        let error_msg = format!("Error processing memes: {}", e);
-        handle_unmatched_regex_error(file_path, &error_msg)?;
-        Vec::new()
+        // The error from process_memes_with_workflow is already a rich context error
+        // We just need to propagate it.
+        return Err(e);
     } else {
         Vec::new()
     };
diff --git a/crates/poem_yaml_fixer/src/main.rs b/crates/poem_yaml_fixer/src/main.rs
index df45c583b..de13319c2 100644
--- a/crates/poem_yaml_fixer/src/main.rs
+++ b/crates/poem_yaml_fixer/src/main.rs
@@ -1,16 +1,14 @@
 use std::path::PathBuf;
 use clap::Parser;
 use walkdir::WalkDir;
- // Updated import
- // Add this import
-use crate::functions::process_single_poem_file_for_report::process_single_poem_file_for_report; // Add this import
+use serde::{Serialize, Deserialize};
 
+use crate::functions::process_single_poem_file_for_report::process_single_poem_file_for_report;
 
-poem_macros::poem_header!(); // Call the header macro once
+poem_macros::poem_header!();
 
-mod functions; // Declare the functions module once
+mod functions;
 
-// Add Cli struct
 #[derive(Parser, Debug)]
 #[command(author, version, about, long_about = None)]
 struct Cli {
@@ -35,55 +33,111 @@ struct Cli {
     fast_parse: bool,
 }
 
+#[derive(Debug, Serialize, Deserialize)]
+struct PoemReportEntry {
+    file_path: String,
+    status: String,
+    matched_patterns: Option<Vec<String>>,
+    error_message: Option<String>,
+    extracted_words_count: Option<usize>,
+    dry_run_changes_applied: bool,
+}
+
+#[derive(Debug, Serialize, Deserialize)]
+struct PoemReport {
+    files: Vec<PoemReportEntry>,
+}
+
 fn main() -> anyhow::Result<()> {
     let cli = Cli::parse();
 
     let current_dir = std::env::current_dir()?;
     let poems_dir = current_dir.join("docs").join("poems");
 
-    let mut regex_config = get_default_regex_config(); // Get default config from macro
+    let mut regex_config = get_default_regex_config();
 
-    // Check for an external regex_config.toml in the current directory
     let external_config_path = current_dir.join("regex_config.toml");
     if external_config_path.exists() {
         println!("Loading external regex config from: {external_config_path:?}");
         let external_config = functions::load_regex_config::load_regex_config(&external_config_path)?;
 
-        // Merge external config into default config (external overrides defaults by name)
         for external_entry in external_config.regexes {
             if let Some(default_entry) = regex_config.regexes.iter_mut().find(|e| e.name == external_entry.name) {
-                *default_entry = external_entry; // Override existing entry
+                *default_entry = external_entry;
             } else {
-                regex_config.regexes.push(external_entry); // Add new entry
+                regex_config.regexes.push(external_entry);
             }
         }
     }
 
-    use crate::functions::types::PoemFunctionRegistry; // Import PoemFunctionRegistry
-    let function_registry: PoemFunctionRegistry = create_function_registry(); // Use PoemFunctionRegistry
+    use crate::functions::types::PoemFunctionRegistry;
+    let function_registry: PoemFunctionRegistry = create_function_registry();
+
+    let mut report_entries: Vec<PoemReportEntry> = Vec::new();
 
     if cli.fast_parse {
         let file_path = cli.file.ok_or_else(|| anyhow::anyhow!("A file path must be provided for fast parsing."))?;
-        let matched_regexes = process_single_poem_file_for_report(
+        match process_single_poem_file_for_report(
             &file_path,
             &regex_config,
             &function_registry,
             cli.debug,
-        )?;
-        println!("Report for {file_path:?}: Matched Regexes: {matched_regexes:?}");
+        ) {
+            Ok(matched_regexes) => {
+                report_entries.push(PoemReportEntry {
+                    file_path: file_path.to_string_lossy().into_owned(),
+                    status: "Success".to_string(),
+                    matched_patterns: Some(matched_regexes),
+                    error_message: None,
+                    extracted_words_count: None, // Not directly available from this function
+                    dry_run_changes_applied: true,
+                });
+            }
+            Err(e) => {
+                report_entries.push(PoemReportEntry {
+                    file_path: file_path.to_string_lossy().into_owned(),
+                    status: "Failed".to_string(),
+                    matched_patterns: None,
+                    error_message: Some(format!("{}", e)),
+                    extracted_words_count: None,
+                    dry_run_changes_applied: false,
+                });
+            }
+        }
     } else if let Some(file_path) = cli.file {
-        functions::process_poem_file::process_poem_file(
+        // This branch calls process_poem_file which doesn't return matched regexes directly
+        // For now, we'll just report success/failure based on the function's result
+        let result = functions::process_poem_file::process_poem_file(
             &file_path,
             cli.max_change_percentage,
             cli.debug,
-            cli.dry_run, // Pass dry_run
+            cli.dry_run,
             &regex_config,
             &function_registry,
-        )?;
+        );
+        match result {
+            Ok(_) => {
+                report_entries.push(PoemReportEntry {
+                    file_path: file_path.to_string_lossy().into_owned(),
+                    status: "Success".to_string(),
+                    matched_patterns: None,
+                    error_message: None,
+                    extracted_words_count: None,
+                    dry_run_changes_applied: cli.dry_run,
+                });
+            }
+            Err(e) => {
+                report_entries.push(PoemReportEntry {
+                    file_path: file_path.to_string_lossy().into_owned(),
+                    status: "Failed".to_string(),
+                    matched_patterns: None,
+                    error_message: Some(format!("{}", e)),
+                    extracted_words_count: None,
+                    dry_run_changes_applied: cli.dry_run,
+                });
+            }
+        }
     } else {
-        let mut all_matched_regexes: std::collections::HashMap<PathBuf, Vec<String>> = std::collections::HashMap::new();
-        let mut failed_files: std::collections::HashMap<PathBuf, String> = std::collections::HashMap::new(); // To store files that failed processing
-
         for entry in WalkDir::new(&poems_dir).into_iter().filter_map(|e| e.ok()) {
             let path = entry.path();
             if path.is_file() && path.extension().is_some_and(|ext| ext == "md") {
@@ -98,35 +152,36 @@ fn main() -> anyhow::Result<()> {
                     cli.debug,
                 ) {
                     Ok(matched_regexes) => {
-                        all_matched_regexes.insert(path.to_path_buf(), matched_regexes);
+                        report_entries.push(PoemReportEntry {
+                            file_path: path.to_string_lossy().into_owned(),
+                            status: "Success".to_string(),
+                            matched_patterns: Some(matched_regexes),
+                            error_message: None,
+                            extracted_words_count: None, // Not directly available from this function
+                            dry_run_changes_applied: true,
+                        });
                     }
                     Err(e) => {
-                        failed_files.insert(path.to_path_buf(), format!("{}", e));
+                        report_entries.push(PoemReportEntry {
+                            file_path: path.to_string_lossy().into_owned(),
+                            status: "Failed".to_string(),
+                            matched_patterns: None,
+                            error_message: Some(format!("{}", e)),
+                            extracted_words_count: None,
+                            dry_run_changes_applied: false,
+                        });
                     }
                 }
             }
         }
+    }
 
-        // Generate summary report
-        println!("\n--- Summary Report ---");
-        for (file_path, matched_regexes) in all_matched_regexes {
-            println!("File: {:?}", file_path);
-            if matched_regexes.is_empty() {
-                println!("  No regexes matched.");
-            } else {
-                println!("  Matched Regexes: {:?}", matched_regexes);
-            }
-        }
+    let report = PoemReport { files: report_entries };
+    let report_yaml = serde_yaml::to_string(&report)?;
+    let report_path = current_dir.join("poem_processing_report.yaml");
+    std::fs::write(&report_path, report_yaml)?;
 
-        if !failed_files.is_empty() {
-            println!("\n--- Files that Failed Processing ---");
-            for (file_path, error_msg) in failed_files {
-                println!("File: {:?}", file_path);
-                println!("  Error: {}", error_msg);
-            }
-        }
-        println!("----------------------");
-    }
+    println!("Report generated at: {:?}", report_path);
 
     Ok(())
 }
diff --git a/docs/poems/quality_procedures_sonnet.md b/docs/poems/quality_procedures_sonnet.md
index e23b2b373..a106cd50a 100644
--- a/docs/poems/quality_procedures_sonnet.md
+++ b/docs/poems/quality_procedures_sonnet.md
@@ -5,11 +5,11 @@ keywords: quality procedures, `ragit` search, one declaration per file, `PathBuf
 emojis: ✅💻🔎✨
 art_generator_instructions: A stylized, glowing codebase, with each file clearly labeled and containing a single, luminous declaration. A `ragit` search beam is illuminating hidden answers within the code. `PathBuf` is represented by a strong, consistent pathway. `From` traits are seen as graceful transformations of errors into clear, defined forms. `cargo check` is a gentle, guiding light, while `cargo run` is a powerful, purposeful flow. The overall feeling should be one of precision, elegance, and the beauty of a well-engineered system.
 memes:
-- description: My quality procedures are so good, they're poetic.
+- description: "My quality procedures are so good, they're poetic."
   template: Success Kid meme
-- description: When your code is so clean, it's basically a sonnet.
+- description: "When your code is so clean, it's basically a sonnet."
   template: Doge meme
-- description: '`cargo check` vs. `cargo run`: The ultimate philosophical debate.'
+- description: "`cargo check` vs. `cargo run`: The ultimate philosophical debate."
   template: Expanding Brain meme
 poem_body: |-
   ## The Quality's Steadfast Code
diff --git a/docs/poems/version_control_sonnet.md b/docs/poems/version_control_sonnet.md
index 7a863c58c..416ab3c8b 100644
--- a/docs/poems/version_control_sonnet.md
+++ b/docs/poems/version_control_sonnet.md
@@ -5,9 +5,12 @@ keywords: version control, sonnet, changes, collaboration, history, commits, con
 emojis: 🌳📜✨✅
 art_generator_instructions: A stylized, glowing tree (representing version control) with branches extending outwards, each branch representing a different version or commit. Hands (representing collaborators) are seen contributing to the tree, and conflicts are resolved as tangled branches gracefully untangle and merge. The overall feeling should be one of order, collaboration, and the continuous growth of a robust system.
 memes:
-  - "My version control is so good, it's poetic." (Success Kid meme)
-  - "When your `git` history is a work of art." (Doge meme)
-  - "Version control: The ultimate time machine for your code." (Expanding Brain meme)
+  - description: "My version control is so good, it's poetic."
+    template: Success Kid meme
+  - description: "When your `git` history is a work of art."
+    template: Doge meme
+  - description: "Version control: The ultimate time machine for your code."
+    template: Expanding Brain meme
 ---
 ## The Version's Steady Hand
 
diff --git a/minizinc_data/huggingface b/minizinc_data/huggingface
--- a/minizinc_data/huggingface
+++ b/minizinc_data/huggingface
@@ -1 +1 @@
-Subproject commit 05aabccff794b68d907eff8528dd0f76767d5fff
+Subproject commit 05aabccff794b68d907eff8528dd0f76767d5fff-dirty
diff --git a/vendor/Ipopt b/vendor/Ipopt
--- a/vendor/Ipopt
+++ b/vendor/Ipopt
@@ -1 +1 @@
-Subproject commit 8b54331f124d1e143a48e5c830ae63d605328d04
+Subproject commit 8b54331f124d1e143a48e5c830ae63d605328d04-dirty
diff --git a/vendor/grex b/vendor/grex
--- a/vendor/grex
+++ b/vendor/grex
@@ -1 +1 @@
-Subproject commit cb71c10815e2216f4941f0b52154fb5d1fc0a01c
+Subproject commit cb71c10815e2216f4941f0b52154fb5d1fc0a01c-dirty
diff --git a/vendor/minizin-js b/vendor/minizin-js
--- a/vendor/minizin-js
+++ b/vendor/minizin-js
@@ -1 +1 @@
-Subproject commit e847b60c09cef981591865606dd7ddc3504ccffe
+Subproject commit e847b60c09cef981591865606dd7ddc3504ccffe-dirty
diff --git a/vendor/minizinc-jll b/vendor/minizinc-jll
--- a/vendor/minizinc-jll
+++ b/vendor/minizinc-jll
@@ -1 +1 @@
-Subproject commit 723b04517fa82b0b03a918b1a04d057e6485be75
+Subproject commit 723b04517fa82b0b03a918b1a04d057e6485be75-dirty
diff --git a/vendor/minizinc-python b/vendor/minizinc-python
--- a/vendor/minizinc-python
+++ b/vendor/minizinc-python
@@ -1 +1 @@
-Subproject commit 9dc56a120fbec5dc8fa7b2b6217c61dccaa7ce53
+Subproject commit 9dc56a120fbec5dc8fa7b2b6217c61dccaa7ce53-dirty
