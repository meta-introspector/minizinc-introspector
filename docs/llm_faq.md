# LLM-FAQ: Open Questions on the Project Vision

This document outlines open questions and areas for further clarification regarding the project's vision as a quasi-meta computationally self-aware system driven by profile-driven LLM agents.

## 1. "Tapestry of Fates" and "Additive Vibes"

*   How are "additive vibes" formally defined, measured, and generated by LLMs from MiniZinc results?
*   What is the precise mathematical structure of the "quasi meta fiber bundle" and its relation to the high-dimensional embedding space?
*   How are prime numbers practically used to represent "irreducible semantic dimensions"?

## 2. "Knowledge Compression: The Codec"

*   [What are the technical specifications and practical implementation of the "codec"?](faq/codec.md)

## 3. "AI-Driven Evolution via LLM Agents"

*   What are the defined "profiles" for LLM agents, and how do they influence agent behavior and task execution?
*   What are the specific criteria and methodologies for "onboarding and training" LLM agents on the codebase and documentation?
*   How will "semantic resonance mapping" be performed, evaluated, and refined?
*   What is the detailed process for LLMs to "refine MiniZinc models," and what metrics are used for correctness, expressiveness, and solver efficiency?
*   What are the technical challenges and proposed solutions for LLMs to generate Rust code for "LLVM Intermediate Representation (IR) to MiniZinc transformation rules" and FFI interactions?
*   Describe the key components and feedback mechanisms of the "robust continuous integration (CI) pipeline" for LLM-generated code.
*   How will "structured feedback" (e.g., test failures, linter warnings, human reviews) be provided to LLM agents to enable iterative rewriting?
*   What specific tools and methodologies will LLMs employ for "performance profiling" and suggesting optimizations?
*   How will the "semantic memory layout" be implemented, and what are the practical implications of moving away from traditional linear addressing?
*   What are the strategies for LLMs to enhance "error handling" and propose "code deduplication and refactoring" opportunities?
*   How will the system "continuously learn from its own development cycles" and adapt its strategies? What types of "formal proofs" will be generated for code or MiniZinc model properties?

## 4. "Quasi-Meta Computational Self-Awareness"

*   What constitutes "computational self-awareness" in this context, and how will its presence or level be measured and demonstrated?
*   How will the system "reason about its own logical structures and meaning"?
*   What are the mechanisms for LLMs to "dynamically update MiniZinc models" based on evolving knowledge?
*   What are the mathematical and computational details of embedding lambda calculus expressions onto a "unitary Riemannian manifold in 8D"?
*   How will the "geometrically meaningful representations" practically enhance AI reasoning over symbolic logic, code understanding, and theorem proving?
