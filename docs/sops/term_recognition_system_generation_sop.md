# Standard Operating Procedure: Term Recognition System Generation and Modification

## 1. Overview

This SOP details the process for generating and modifying the term recognition system used within the project. This system is designed to efficiently identify and process terms from various sources, particularly for code analysis and semantic understanding. It addresses challenges related to large term lists and memory constraints by employing a modular, chunk-based generation approach.

## 2. System Components

The term recognition system primarily involves two Rust crates and a configuration file:

### 2.1. `crates/zos-fast-query`

This crate is responsible for the core term recognition logic and orchestrates the generation of term data during its build process.

*   **`build.rs`**: The build script for `zos-fast-query`. It reads configuration, loads and filters terms, orchestrates the chunking of terms into smaller JSON files, and generates a Rust index file (`generated_recognizer.rs`) that lists these term data files.
*   **`build_utils.rs`**: Contains utility functions, notably `sanitize_filename_char` and `sanitize_filename`, used for creating compatible filenames from potentially problematic characters (e.g., Unicode).
*   **`term_loader.rs`**: Handles loading the raw term index (e.g., `hierarchical_term_index.json`) and filtering out "junk" terms based on predefined criteria (e.g., length, purely numeric/hex, non-alphanumeric proportion). It also enforces a `MAX_TOTAL_TERMS` limit.
*   **`chunk_generator.rs`**: Takes the filtered terms and splits them into smaller, manageable JSON files (chunks). It organizes these chunks based on the first character of the terms and enforces a `MAX_TERMS_PER_CHUNK` limit, further subdividing if necessary.
*   **`index_writer.rs`**: Generates the `generated_recognizer.rs` file. This file is a Rust source file that contains a `pub const` array of all the generated term chunk filenames. It uses a template (`recognizer_template.rs`) for structured output.
*   **`recognizer_template.rs`**: A template file used by `index_writer.rs` to generate `generated_recognizer.rs`. It contains a placeholder (`// GENERATED_TERM_FILES_PLACEHOLDER`) where the list of term filenames is inserted.
*   **`src/recognizer/mod.rs`**: The runtime component that utilizes the generated term data. It includes `generated_recognizer.rs` and implements the `TermRecognizer` struct, which loads terms from the generated JSON chunks on demand for efficient lookup.

### 2.2. `crates/vocabulary_dfa_generator`

This crate is a separate binary responsible for generating Deterministic Finite Automata (DFA) modules. It reads a list of terms and creates Rust files containing regular expressions for efficient pattern matching. It also sanitizes filenames and organizes output into subdirectories.

*   **`src/main.rs`**: The main logic for generating DFA modules. It reads terms, filters them, sanitizes filenames, and writes Rust files containing DFA logic into a hierarchical directory structure.

### 2.3. `build_config.toml`

Located at the project root (`/data/data/com.termux/files/home/storage/github/libminizinc/build_config.toml`), this TOML file centralizes configuration for the build process, particularly defining key absolute paths used by both `zos-fast-query` and `vocabulary_dfa_generator`.

Example `build_config.toml` content:
```toml
[paths]
home_dir = "/data/data/com.termux/files/home/"
github_root = "/data/data/com.termux/files/home/storage/github/"
project_root = "/data/data/com.termux/files/home/storage/github/libminizinc/"
hierarchical_term_index = "/data/data/com.termux/files/home/storage/github/hierarchical_term_index.json"
```

## 3. Generation Process

The term recognition system's data (term chunks and index) is generated as part of the `zos-fast-query` crate's build process. The DFA modules are generated by running `vocabulary_dfa_generator`.

### 3.1. Term Data Generation (`zos-fast-query`)

To generate or regenerate the term data and index:

1.  **Ensure `build_config.toml` is correctly configured.**
2.  **Run the build command for `zos-fast-query`:**
    ```bash
    cargo build --package zos-fast-query
    ```
    This command triggers `zos-fast-query/build.rs`, which performs the following:
    *   Reads `build_config.toml` to get necessary paths.
    *   Loads and filters terms from the `hierarchical_term_index.json` file (path specified in `build_config.toml`).
    *   Splits filtered terms into JSON chunks based on `MAX_TERMS_PER_CHUNK` (defined in `chunk_generator.rs`) and writes them to the `OUT_DIR` (Cargo's build output directory).
    *   Generates `generated_recognizer.rs` in the `OUT_DIR`, containing an array of the generated JSON chunk filenames.

### 3.2. DFA Module Generation (`vocabulary_dfa_generator`)

To generate or regenerate the DFA modules:

1.  **Ensure `build_config.toml` is correctly configured.**
2.  **Run the `vocabulary_dfa_generator` binary:**
    ```bash
    cargo run --package vocabulary_dfa_generator
    ```
    This command executes `vocabulary_dfa_generator/src/main.rs`, which performs the following:
    *   Reads `build_config.toml` to get input (`all_terms.txt`) and output paths.
    *   Loads and filters terms from `all_terms.txt`.
    *   Generates `.rs` files containing DFA logic, organizing them into subdirectories (e.g., `crates/vocabulary_dfa_lib/src/a/`) and sanitizing filenames (e.g., `aU02C7_dfa.rs`).

## 4. Modification Process

### 4.1. Modifying Term Lists

*   **`hierarchical_term_index.json`**: This is the primary source for terms used by `zos-fast-query`. Modifications to this file will trigger a regeneration of term data when `zos-fast-query` is rebuilt.
*   **`all_terms.txt`**: This is the primary source for terms used by `vocabulary_dfa_generator`. Modifications to this file will trigger a regeneration of DFA modules when `vocabulary_dfa_generator` is run.

### 4.2. Adjusting Generation Parameters

*   **`MAX_TOTAL_TERMS`**: (in `term_loader.rs`) Controls the maximum number of terms `zos-fast-query` will process. If the filtered term count exceeds this, the build will fail.
*   **`MAX_TERMS_PER_CHUNK`**: (in `chunk_generator.rs`) Controls the maximum number of terms in each generated JSON chunk for `zos-fast-query`. Adjust this to fine-tune memory usage during runtime.
*   **`MAX_TERMS_PER_FILE`**: (in `vocabulary_dfa_generator/src/main.rs`) Controls the maximum number of terms in each generated DFA `.rs` file. Adjust this to manage the size of individual DFA files.

### 4.3. Filename Sanitization

The `sanitize_filename_char` and `sanitize_filename` functions (in `build_utils.rs` for `zos-fast-query` and directly in `main.rs` for `vocabulary_dfa_generator`) are crucial for ensuring compatible filenames. If new problematic characters arise or a different sanitization strategy is desired, these functions should be updated.

## 5. Helper Scripts (Proposed)

To streamline common tasks, the following helper scripts can be created:

### 5.1. `scripts/clean_generated_files.sh`

This script would remove all previously generated term chunks and DFA modules, ensuring a clean regeneration.

```bash
#!/bin/bash
# Cleans generated term chunks and DFA modules

# Get project root from build_config.toml (assuming it's at libminizinc root)
PROJECT_ROOT=$(grep -E '^project_root' build_config.toml | cut -d'=' -f2 | tr -d ' "')

# Remove zos-fast-query generated files
rm -rf "${PROJECT_ROOT}target/debug/build/zos-fast-query-*/out/"
rm -rf "${PROJECT_ROOT}target/release/build/zos-fast-query-*/out/"

# Remove vocabulary_dfa_lib generated subdirectories
# A safer approach might be to list directories and filter
find "${PROJECT_ROOT}crates/vocabulary_dfa_lib/src/" -maxdepth 1 -type d -name '[a-z]' -exec rm -rf {} + 
find "${PROJECT_ROOT}crates/vocabulary_dfa_lib/src/" -maxdepth 1 -type d -name '[0-9]' -exec rm -rf {} + 
find "${PROJECT_ROOT}crates/vocabulary_dfa_lib/src/" -maxdepth 1 -type d -name 'U*' -exec rm -rf {} + 

echo "Cleaned generated files."
```

### 5.2. `scripts/regenerate_all_terms.sh`

This script would run both generators.

```bash
#!/bin/bash
# Regenerates all term data and DFA modules

echo "Regenerating zos-fast-query term data..."
cargo build --package zos-fast-query

echo "Regenerating vocabulary_dfa_modules..."
cargo run --package vocabulary_dfa_generator

echo "All term data and DFA modules regenerated."
```

## 6. Troubleshooting

*   **Memory Errors during Build (`zos-fast-query`)**: 
    *   **Cause**: `hierarchical_term_index.json` is too large, or `MAX_TOTAL_TERMS` is set too high.
    *   **Solution**: Reduce the size of `hierarchical_term_index.json` by filtering more terms, or increase `MAX_TOTAL_TERMS` if system memory allows. Consider optimizing `is_junk_term` or the initial term collection process.
*   **Memory Errors during Runtime (`zos-fast-query`)**: 
    *   **Cause**: `MAX_TERMS_PER_CHUNK` is too high, leading to large JSON files being loaded into memory.
    *   **Solution**: Reduce `MAX_TERMS_PER_CHUNK` in `chunk_generator.rs`. This will create more, smaller JSON files, reducing the memory footprint of individual chunks.
*   **Malformed Generated Files (`generated_recognizer.rs`)**: 
    *   **Cause**: Errors in `index_writer.rs` or `recognizer_template.rs` leading to invalid Rust syntax.
    *   **Solution**: Carefully review the `format!` strings and placeholder replacement logic in `index_writer.rs` and the template content in `recognizer_template.rs`.
*   **Problematic Filenames (`vocabulary_dfa_lib`)**: 
    *   **Cause**: Non-ASCII characters in terms are not being correctly sanitized, or old files with problematic names persist.
    *   **Solution**: Ensure `sanitize_filename_char` and `sanitize_filename` functions are robust. Run `scripts/clean_generated_files.sh` and then `scripts/regenerate_all_terms.sh` to ensure a clean regeneration.